{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1541af79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8540eb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '_io.StringIO'>\n"
     ]
    }
   ],
   "source": [
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "import io\n",
    "import os\n",
    "\n",
    "fp = open('clause.pdf', 'rb')\n",
    "rsrcmgr = PDFResourceManager()\n",
    "retstr = io.StringIO()\n",
    "print(type(retstr))\n",
    "codec = 'utf-8'\n",
    "laparams = LAParams()\n",
    "device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
    "interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "para_dict = {}\n",
    "page_no = 0\n",
    "for pageNumber, page in enumerate(PDFPage.get_pages(fp)):\n",
    "    if pageNumber == page_no:\n",
    "        interpreter.process_page(page)\n",
    "        data = retstr.getvalue()\n",
    "        data = data.split('\\n\\n')\n",
    "        para_dict[page_no] = data\n",
    "        retstr.truncate(0)\n",
    "        retstr.seek(0)\n",
    "\n",
    "    page_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302dbf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering short sentences as they are mostly titles and sub headings. \n",
    "sentence_list = []\n",
    "for key, values in list(para_dict.items()):\n",
    "    for sentence in values:\n",
    "        if len(sentence.split()) < 5:\n",
    "            values.remove(sentence)\n",
    "        else: \n",
    "            sentence = re.sub('\\n|\\x0c', ' ', sentence)\n",
    "            sentence_list.append(sentence)\n",
    "            \n",
    "    para_dict[key] = sentence_list\n",
    "    sentence_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48551af",
   "metadata": {},
   "source": [
    "#### Questions \n",
    "* When will be the termination date?\n",
    "* How are the payments made?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58bcfa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ques1 = \"When will be the termination date?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b82c622",
   "metadata": {},
   "source": [
    "### Finding top 30 similar paragraphs for question 1 using Tfidf and cosine Similarity\n",
    "\n",
    "#### *When will be the termination date?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c141c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/syamprakash/opt/miniconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/syamprakash/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk, string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nltk.download('punkt') # if necessary...\n",
    "\n",
    "\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "remove_punctuation_map = dict((ord(char), None) for char in string.punctuation)\n",
    "\n",
    "def stem_tokens(tokens):\n",
    "    return [stemmer.stem(item) for item in tokens]\n",
    "\n",
    "'''remove punctuation, lowercase, stem'''\n",
    "def normalize(text):\n",
    "    return stem_tokens(nltk.word_tokenize(text.lower().translate(remove_punctuation_map)))\n",
    "\n",
    "vectorizer = TfidfVectorizer(tokenizer=normalize, stop_words='english')\n",
    "\n",
    "def cosine_sim(text1, text2):\n",
    "    tfidf = vectorizer.fit_transform([text1, text2])\n",
    "    return ((tfidf * tfidf.T).A)[0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c18a0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc36c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_similarity(ques, text):\n",
    "    ques = nlp(ques)\n",
    "    text = nlp(text)\n",
    "    similarity = ques.similarity(text)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa5c39d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacy_similarity_generator(paragraph_dictionary,ques1):\n",
    "    sim_score_list = {}\n",
    "    sim_dict = {}\n",
    "    for key, values in paragraph_dictionary.items():\n",
    "        for sentence in values:\n",
    "            similarity_score = spacy_similarity(ques1, sentence)\n",
    "            if similarity_score > 0:\n",
    "                sim_score_list[similarity_score] = sentence\n",
    "        sim_dict[key] = sim_score_list\n",
    "        sim_score_list = {}\n",
    "        return sim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "738e8dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_cosine_similarity_generator(paragraph_dictionary,ques1):\n",
    "    sim_score_list = {}\n",
    "    sim_dict = {}\n",
    "    for key, values in para_dict.items():\n",
    "        for sentence in values:\n",
    "            similarity_score = cosine_sim(ques1, sentence)\n",
    "            if similarity_score > 0:\n",
    "                sim_score_list[similarity_score] = sentence\n",
    "        sim_dict[key] = sim_score_list\n",
    "        sim_score_list = {}\n",
    "    return sim_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73790957",
   "metadata": {},
   "source": [
    "### Setting up the Bert model pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dac2c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForQuestionAnswering, AutoTokenizer\n",
    "modelname = 'deepset/bert-base-cased-squad2'\n",
    "model = BertForQuestionAnswering.from_pretrained(modelname)\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9efafacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "nlp = pipeline('question-answering', model=model, tokenizer=tokenizer, top_k = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "277ed180",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/syamprakash/opt/miniconda3/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tfidf_sim_dict = tfidf_cosine_similarity_generator(para_dict,ques1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c236b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_values_list = []\n",
    "for key, values in tfidf_sim_dict.items():\n",
    "    if len(values.values())>0:\n",
    "        page_number = key\n",
    "        paragraph = list(values.values())[0]\n",
    "        similarity_score = list(values.keys())[0]\n",
    "        key_values_list.append([page_number,paragraph,similarity_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f22d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(key_values_list, columns = ['Page Number','Paragraph','Similarity Score'])\n",
    "df['Length'] = df['Paragraph'].str.len() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54b586f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Start Logits'] = 0\n",
    "for i in range(1,len(df)):\n",
    "    df.loc[i,'Start Logits'] = df.loc[i-1,'Length']+df.loc[i-1,'Start Logits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42eaff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['End Logits'] = df['Length'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "859a6032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page Number</th>\n",
       "      <th>Paragraph</th>\n",
       "      <th>Similarity Score</th>\n",
       "      <th>Length</th>\n",
       "      <th>Start Logits</th>\n",
       "      <th>End Logits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>awarded Vendor shall, at their sole expense, m...</td>\n",
       "      <td>0.072147</td>\n",
       "      <td>2383</td>\n",
       "      <td>4523</td>\n",
       "      <td>6906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27</td>\n",
       "      <td>552 CFR PART 200 ContractsContracts for more t...</td>\n",
       "      <td>0.064023</td>\n",
       "      <td>3003</td>\n",
       "      <td>6906</td>\n",
       "      <td>9909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>38</td>\n",
       "      <td>82Texas Business and Commerce Code ยง 272 Requi...</td>\n",
       "      <td>0.017423</td>\n",
       "      <td>2593</td>\n",
       "      <td>9909</td>\n",
       "      <td>12502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40</td>\n",
       "      <td>89Felony Conviction NoticeTexas Education Code...</td>\n",
       "      <td>0.013465</td>\n",
       "      <td>2997</td>\n",
       "      <td>12502</td>\n",
       "      <td>15499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43</td>\n",
       "      <td>101CERTIFICATION PROHIBITING DISCRIMINATION AG...</td>\n",
       "      <td>0.017007</td>\n",
       "      <td>4906</td>\n",
       "      <td>15499</td>\n",
       "      <td>20405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Page Number                                          Paragraph  \\\n",
       "4            7  awarded Vendor shall, at their sole expense, m...   \n",
       "5           27  552 CFR PART 200 ContractsContracts for more t...   \n",
       "6           38  82Texas Business and Commerce Code ยง 272 Requi...   \n",
       "7           40  89Felony Conviction NoticeTexas Education Code...   \n",
       "8           43  101CERTIFICATION PROHIBITING DISCRIMINATION AG...   \n",
       "\n",
       "   Similarity Score  Length  Start Logits  End Logits  \n",
       "4          0.072147    2383          4523        6906  \n",
       "5          0.064023    3003          6906        9909  \n",
       "6          0.017423    2593          9909       12502  \n",
       "7          0.013465    2997         12502       15499  \n",
       "8          0.017007    4906         15499       20405  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbfb383b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\n",
    "for key, values in tfidf_sim_dict.items():\n",
    "    for sentences in values.values():\n",
    "        text = text+\". \"+sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4452855",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = text\n",
    "predicted_answers = nlp({\n",
    "    'question': ques1,\n",
    "    'context': context\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "271e3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_answer = pd.DataFrame(predicted_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1b5b3b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.646293</td>\n",
       "      <td>4943</td>\n",
       "      <td>4955</td>\n",
       "      <td>one (1) year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.519622</td>\n",
       "      <td>4943</td>\n",
       "      <td>4955</td>\n",
       "      <td>one (1) year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.168845</td>\n",
       "      <td>734</td>\n",
       "      <td>802</td>\n",
       "      <td>the last day of the month of the  month of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.132105</td>\n",
       "      <td>738</td>\n",
       "      <td>802</td>\n",
       "      <td>last day of the month of the  month of the ori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.120970</td>\n",
       "      <td>4943</td>\n",
       "      <td>4997</td>\n",
       "      <td>one (1) year from the effective  date  of  ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.097723</td>\n",
       "      <td>734</td>\n",
       "      <td>773</td>\n",
       "      <td>the last day of the month of the  month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.078935</td>\n",
       "      <td>4948</td>\n",
       "      <td>4955</td>\n",
       "      <td>1) year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.076459</td>\n",
       "      <td>738</td>\n",
       "      <td>773</td>\n",
       "      <td>last day of the month of the  month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.054853</td>\n",
       "      <td>4943</td>\n",
       "      <td>4998</td>\n",
       "      <td>one (1) year from the effective  date  of  ter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.044819</td>\n",
       "      <td>4931</td>\n",
       "      <td>4955</td>\n",
       "      <td>a period of one (1) year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      score  start   end                                             answer\n",
       "0  0.646293   4943  4955                                       one (1) year\n",
       "1  0.519622   4943  4955                                       one (1) year\n",
       "2  0.168845    734   802  the last day of the month of the  month of the...\n",
       "3  0.132105    738   802  last day of the month of the  month of the ori...\n",
       "4  0.120970   4943  4997  one (1) year from the effective  date  of  ter...\n",
       "5  0.097723    734   773            the last day of the month of the  month\n",
       "6  0.078935   4948  4955                                            1) year\n",
       "7  0.076459    738   773                last day of the month of the  month\n",
       "8  0.054853   4943  4998  one (1) year from the effective  date  of  ter...\n",
       "9  0.044819   4931  4955                           a period of one (1) year"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11178a29",
   "metadata": {},
   "source": [
    "The required answer here is \"One(1) year\". We can adjust topk according to our need to remove duplicates\n",
    "\n",
    "##### To improve this feature we can join the paragraph data and bert output to find which paragraph lies in. Another way of enhancing this feature would be to backtrack to the PDF and highlight the portion where the answer lies using tools like PDF-plumber. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7b5f02",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
